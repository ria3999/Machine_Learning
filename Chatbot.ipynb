{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNe6O08cGNNVlwXL9Uabd9H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ria3999/mahine_learning-codes/blob/master/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynB2jr20nas8",
        "outputId": "7975c98f-eff6-40ef-9acb-de12b7ce4f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wugAFvNyniId"
      },
      "source": [
        "stemmer=LancasterStemmer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA1miIa1P1uQ",
        "outputId": "51fa7e44-80e9-483d-d40f-c2649c00f586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "pip install tflearn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.3.2-cp36-none-any.whl size=128207 sha256=caf6d1a8c747e92b40e19d43c7db559946732753a5ad895d41b95484ea4efd7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV5Kcm8bQhRO",
        "outputId": "c6dd0804-a0f1-4326-a59c-679078046a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "pip uninstall tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "  Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7KzmFNaQiv9",
        "outputId": "77aa8ea6-6e3e-4cee-9e8a-09f49899bbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "pip install tensorflow==1.13.2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/d3/651f95288a6cd9094f7411cdd90ef12a3d01a268009e0e3cd66b5c8d65bd/tensorflow-1.13.2-cp36-cp36m-manylinux1_x86_64.whl (92.6MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.35.1)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 40.2MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (3.12.4)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.0)\n",
            "Installing collected packages: mock, tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwgq20J3PkLs",
        "outputId": "8a1dc6bf-838d-4ea1-c988-90a4af9857c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3anuvpsVPwEC",
        "outputId": "3e5903b0-a895-4569-92b9-df0f9a8ee9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import tflearn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-dSlpNhQAer"
      },
      "source": [
        "with open('/content/intents.json') as json_data:\n",
        "  intents=json.load(json_data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRFgrlyXUj2j",
        "outputId": "506d3be6-648d-480f-a603-1652b3ee6683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "intents"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'context': [''],\n",
              "   'patterns': ['Hi there',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hey',\n",
              "    'Hola',\n",
              "    'Hello',\n",
              "    'Good day'],\n",
              "   'responses': ['Hello, thanks for asking',\n",
              "    'Good to see you again',\n",
              "    'Hi there, how can I help?'],\n",
              "   'tag': 'greeting'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Bye',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'Nice chatting to you, bye',\n",
              "    'Till next time'],\n",
              "   'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'],\n",
              "   'tag': 'goodbye'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Thanks',\n",
              "    'Thank you',\n",
              "    \"That's helpful\",\n",
              "    'Awesome, thanks',\n",
              "    'Thanks for helping me'],\n",
              "   'responses': ['Happy to help!', 'Any time!', 'My pleasure'],\n",
              "   'tag': 'thanks'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': [\"Sorry, can't understand you\",\n",
              "    'Please give me more info',\n",
              "    'Not sure I understand'],\n",
              "   'tag': 'noanswer'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['How you could help me?',\n",
              "    'What you can do?',\n",
              "    'What help you provide?',\n",
              "    'How you can be helpful?',\n",
              "    'What support is offered'],\n",
              "   'responses': ['I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies',\n",
              "    'Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies'],\n",
              "   'tag': 'options'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['How to check Adverse drug reaction?',\n",
              "    'Open adverse drugs module',\n",
              "    'Give me a list of drugs causing adverse behavior',\n",
              "    'List all drugs suitable for patient with adverse reaction',\n",
              "    'Which drugs dont have adverse reaction?'],\n",
              "   'responses': ['Navigating to Adverse drug reaction module'],\n",
              "   'tag': 'adverse_drug'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Open blood pressure module',\n",
              "    'Task related to blood pressure',\n",
              "    'Blood pressure data entry',\n",
              "    'I want to log blood pressure results',\n",
              "    'Blood pressure data management'],\n",
              "   'responses': ['Navigating to Blood Pressure module'],\n",
              "   'tag': 'blood_pressure'},\n",
              "  {'context': ['search_blood_pressure_by_patient_id'],\n",
              "   'patterns': ['I want to search for blood pressure result history',\n",
              "    'Blood pressure for patient',\n",
              "    'Load patient blood pressure result',\n",
              "    'Show blood pressure results for patient',\n",
              "    'Find blood pressure results by ID'],\n",
              "   'responses': ['Please provide Patient ID', 'Patient ID?'],\n",
              "   'tag': 'blood_pressure_search'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading Blood pressure result for Patient'],\n",
              "   'tag': 'search_blood_pressure_by_patient_id'},\n",
              "  {'context': ['search_pharmacy_by_name'],\n",
              "   'patterns': ['Find me a pharmacy',\n",
              "    'Find pharmacy',\n",
              "    'List of pharmacies nearby',\n",
              "    'Locate pharmacy',\n",
              "    'Search pharmacy'],\n",
              "   'responses': ['Please provide pharmacy name'],\n",
              "   'tag': 'pharmacy_search'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading pharmacy details'],\n",
              "   'tag': 'search_pharmacy_by_name'},\n",
              "  {'context': ['search_hospital_by_params'],\n",
              "   'patterns': ['Lookup for hospital',\n",
              "    'Searching for hospital to transfer patient',\n",
              "    'I want to search hospital data',\n",
              "    'Hospital lookup for patient',\n",
              "    'Looking up hospital details'],\n",
              "   'responses': ['Please provide hospital name or location'],\n",
              "   'tag': 'hospital_search'},\n",
              "  {'context': ['search_hospital_by_type'],\n",
              "   'patterns': [],\n",
              "   'responses': ['Please provide hospital type'],\n",
              "   'tag': 'search_hospital_by_params'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading hospital details'],\n",
              "   'tag': 'search_hospital_by_type'}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaisFEYhUlJr"
      },
      "source": [
        "words=[]\n",
        "classes=[]\n",
        "documents=[]\n",
        "ignore=['?']\n",
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    w=nltk.word_tokenize(pattern)\n",
        "    words.extend(w)\n",
        "    documents.append((w,intent['tag']))\n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXOdvD1WAUwx",
        "outputId": "5a2ea04e-a5fa-4a53-be2d-7b71e92cd817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['greeting',\n",
              " 'goodbye',\n",
              " 'thanks',\n",
              " 'options',\n",
              " 'adverse_drug',\n",
              " 'blood_pressure',\n",
              " 'blood_pressure_search',\n",
              " 'pharmacy_search',\n",
              " 'hospital_search']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXokiGshAW4g",
        "outputId": "f3e5d337-d8c3-4cb2-b7b8-efda4b35fbf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "words"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'there',\n",
              " 'How',\n",
              " 'are',\n",
              " 'you',\n",
              " 'Is',\n",
              " 'anyone',\n",
              " 'there',\n",
              " '?',\n",
              " 'Hey',\n",
              " 'Hola',\n",
              " 'Hello',\n",
              " 'Good',\n",
              " 'day',\n",
              " 'Bye',\n",
              " 'See',\n",
              " 'you',\n",
              " 'later',\n",
              " 'Goodbye',\n",
              " 'Nice',\n",
              " 'chatting',\n",
              " 'to',\n",
              " 'you',\n",
              " ',',\n",
              " 'bye',\n",
              " 'Till',\n",
              " 'next',\n",
              " 'time',\n",
              " 'Thanks',\n",
              " 'Thank',\n",
              " 'you',\n",
              " 'That',\n",
              " \"'s\",\n",
              " 'helpful',\n",
              " 'Awesome',\n",
              " ',',\n",
              " 'thanks',\n",
              " 'Thanks',\n",
              " 'for',\n",
              " 'helping',\n",
              " 'me',\n",
              " 'How',\n",
              " 'you',\n",
              " 'could',\n",
              " 'help',\n",
              " 'me',\n",
              " '?',\n",
              " 'What',\n",
              " 'you',\n",
              " 'can',\n",
              " 'do',\n",
              " '?',\n",
              " 'What',\n",
              " 'help',\n",
              " 'you',\n",
              " 'provide',\n",
              " '?',\n",
              " 'How',\n",
              " 'you',\n",
              " 'can',\n",
              " 'be',\n",
              " 'helpful',\n",
              " '?',\n",
              " 'What',\n",
              " 'support',\n",
              " 'is',\n",
              " 'offered',\n",
              " 'How',\n",
              " 'to',\n",
              " 'check',\n",
              " 'Adverse',\n",
              " 'drug',\n",
              " 'reaction',\n",
              " '?',\n",
              " 'Open',\n",
              " 'adverse',\n",
              " 'drugs',\n",
              " 'module',\n",
              " 'Give',\n",
              " 'me',\n",
              " 'a',\n",
              " 'list',\n",
              " 'of',\n",
              " 'drugs',\n",
              " 'causing',\n",
              " 'adverse',\n",
              " 'behavior',\n",
              " 'List',\n",
              " 'all',\n",
              " 'drugs',\n",
              " 'suitable',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'with',\n",
              " 'adverse',\n",
              " 'reaction',\n",
              " 'Which',\n",
              " 'drugs',\n",
              " 'dont',\n",
              " 'have',\n",
              " 'adverse',\n",
              " 'reaction',\n",
              " '?',\n",
              " 'Open',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'module',\n",
              " 'Task',\n",
              " 'related',\n",
              " 'to',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'Blood',\n",
              " 'pressure',\n",
              " 'data',\n",
              " 'entry',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'log',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'results',\n",
              " 'Blood',\n",
              " 'pressure',\n",
              " 'data',\n",
              " 'management',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'search',\n",
              " 'for',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'result',\n",
              " 'history',\n",
              " 'Blood',\n",
              " 'pressure',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'Load',\n",
              " 'patient',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'result',\n",
              " 'Show',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'results',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'Find',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'results',\n",
              " 'by',\n",
              " 'ID',\n",
              " 'Find',\n",
              " 'me',\n",
              " 'a',\n",
              " 'pharmacy',\n",
              " 'Find',\n",
              " 'pharmacy',\n",
              " 'List',\n",
              " 'of',\n",
              " 'pharmacies',\n",
              " 'nearby',\n",
              " 'Locate',\n",
              " 'pharmacy',\n",
              " 'Search',\n",
              " 'pharmacy',\n",
              " 'Lookup',\n",
              " 'for',\n",
              " 'hospital',\n",
              " 'Searching',\n",
              " 'for',\n",
              " 'hospital',\n",
              " 'to',\n",
              " 'transfer',\n",
              " 'patient',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'search',\n",
              " 'hospital',\n",
              " 'data',\n",
              " 'Hospital',\n",
              " 'lookup',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'Looking',\n",
              " 'up',\n",
              " 'hospital',\n",
              " 'details']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsIgfXyUAa8E",
        "outputId": "95a8ac6d-6f7f-4bf5-a1da-80528494e612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "documents"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['Hi', 'there'], 'greeting'),\n",
              " (['How', 'are', 'you'], 'greeting'),\n",
              " (['Is', 'anyone', 'there', '?'], 'greeting'),\n",
              " (['Hey'], 'greeting'),\n",
              " (['Hola'], 'greeting'),\n",
              " (['Hello'], 'greeting'),\n",
              " (['Good', 'day'], 'greeting'),\n",
              " (['Bye'], 'goodbye'),\n",
              " (['See', 'you', 'later'], 'goodbye'),\n",
              " (['Goodbye'], 'goodbye'),\n",
              " (['Nice', 'chatting', 'to', 'you', ',', 'bye'], 'goodbye'),\n",
              " (['Till', 'next', 'time'], 'goodbye'),\n",
              " (['Thanks'], 'thanks'),\n",
              " (['Thank', 'you'], 'thanks'),\n",
              " (['That', \"'s\", 'helpful'], 'thanks'),\n",
              " (['Awesome', ',', 'thanks'], 'thanks'),\n",
              " (['Thanks', 'for', 'helping', 'me'], 'thanks'),\n",
              " (['How', 'you', 'could', 'help', 'me', '?'], 'options'),\n",
              " (['What', 'you', 'can', 'do', '?'], 'options'),\n",
              " (['What', 'help', 'you', 'provide', '?'], 'options'),\n",
              " (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'),\n",
              " (['What', 'support', 'is', 'offered'], 'options'),\n",
              " (['How', 'to', 'check', 'Adverse', 'drug', 'reaction', '?'], 'adverse_drug'),\n",
              " (['Open', 'adverse', 'drugs', 'module'], 'adverse_drug'),\n",
              " (['Give', 'me', 'a', 'list', 'of', 'drugs', 'causing', 'adverse', 'behavior'],\n",
              "  'adverse_drug'),\n",
              " (['List',\n",
              "   'all',\n",
              "   'drugs',\n",
              "   'suitable',\n",
              "   'for',\n",
              "   'patient',\n",
              "   'with',\n",
              "   'adverse',\n",
              "   'reaction'],\n",
              "  'adverse_drug'),\n",
              " (['Which', 'drugs', 'dont', 'have', 'adverse', 'reaction', '?'],\n",
              "  'adverse_drug'),\n",
              " (['Open', 'blood', 'pressure', 'module'], 'blood_pressure'),\n",
              " (['Task', 'related', 'to', 'blood', 'pressure'], 'blood_pressure'),\n",
              " (['Blood', 'pressure', 'data', 'entry'], 'blood_pressure'),\n",
              " (['I', 'want', 'to', 'log', 'blood', 'pressure', 'results'],\n",
              "  'blood_pressure'),\n",
              " (['Blood', 'pressure', 'data', 'management'], 'blood_pressure'),\n",
              " (['I',\n",
              "   'want',\n",
              "   'to',\n",
              "   'search',\n",
              "   'for',\n",
              "   'blood',\n",
              "   'pressure',\n",
              "   'result',\n",
              "   'history'],\n",
              "  'blood_pressure_search'),\n",
              " (['Blood', 'pressure', 'for', 'patient'], 'blood_pressure_search'),\n",
              " (['Load', 'patient', 'blood', 'pressure', 'result'], 'blood_pressure_search'),\n",
              " (['Show', 'blood', 'pressure', 'results', 'for', 'patient'],\n",
              "  'blood_pressure_search'),\n",
              " (['Find', 'blood', 'pressure', 'results', 'by', 'ID'],\n",
              "  'blood_pressure_search'),\n",
              " (['Find', 'me', 'a', 'pharmacy'], 'pharmacy_search'),\n",
              " (['Find', 'pharmacy'], 'pharmacy_search'),\n",
              " (['List', 'of', 'pharmacies', 'nearby'], 'pharmacy_search'),\n",
              " (['Locate', 'pharmacy'], 'pharmacy_search'),\n",
              " (['Search', 'pharmacy'], 'pharmacy_search'),\n",
              " (['Lookup', 'for', 'hospital'], 'hospital_search'),\n",
              " (['Searching', 'for', 'hospital', 'to', 'transfer', 'patient'],\n",
              "  'hospital_search'),\n",
              " (['I', 'want', 'to', 'search', 'hospital', 'data'], 'hospital_search'),\n",
              " (['Hospital', 'lookup', 'for', 'patient'], 'hospital_search'),\n",
              " (['Looking', 'up', 'hospital', 'details'], 'hospital_search')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM_42HgsZWT0"
      },
      "source": [
        "words=[stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
        "words=sorted(list(set(words)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifFFHc-hcIiv"
      },
      "source": [
        "classes=sorted(list(set(classes)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igZwq2mBAhEt",
        "outputId": "4d645b84-7189-4a7a-f4f3-1d72d548307b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adverse_drug',\n",
              " 'blood_pressure',\n",
              " 'blood_pressure_search',\n",
              " 'goodbye',\n",
              " 'greeting',\n",
              " 'hospital_search',\n",
              " 'options',\n",
              " 'pharmacy_search',\n",
              " 'thanks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATqSqLLecZi5",
        "outputId": "1e7ae698-cb9c-4183-e381-95ce25032aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(len(documents),\"documents\")\n",
        "print(len(classes),\"classes\",classes)\n",
        "print(len(words),\"unique stemmed words\",words)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47 documents\n",
            "9 classes ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n",
            "84 unique stemmed words [\"'s\", ',', 'a', 'advers', 'al', 'anyon', 'ar', 'awesom', 'be', 'behavy', 'blood', 'by', 'bye', 'can', 'caus', 'chat', 'check', 'could', 'dat', 'day', 'detail', 'do', 'dont', 'drug', 'entry', 'find', 'for', 'giv', 'good', 'goodby', 'hav', 'hello', 'help', 'hey', 'hi', 'hist', 'hol', 'hospit', 'how', 'i', 'id', 'is', 'lat', 'list', 'load', 'loc', 'log', 'look', 'lookup', 'man', 'me', 'mod', 'nearby', 'next', 'nic', 'of', 'off', 'op', 'paty', 'pharm', 'press', 'provid', 'react', 'rel', 'result', 'search', 'see', 'show', 'suit', 'support', 'task', 'thank', 'that', 'ther', 'til', 'tim', 'to', 'transf', 'up', 'want', 'what', 'which', 'with', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyiGAWZvcc7b"
      },
      "source": [
        "training=[]\n",
        "output=[]\n",
        "output_empty=[0]*len(classes)\n",
        "for doc in documents:\n",
        "  bag=[]\n",
        "  pattern_words=doc[0]\n",
        "  pattern_words=[stemmer.stem(word.lower()) for word in pattern_words]\n",
        "  for w in words:\n",
        "    bag.append(1) if w in pattern_words else bag.append(0)\n",
        "  output_row=list(output_empty)\n",
        "  output_row[classes.index(doc[1])]=1\n",
        "  training.append([bag,output_row])\n",
        "random.shuffle(training)\n",
        "training=np.array(training)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Pe7GRGBHJ8",
        "outputId": "cf2a865d-b1d8-418b-9ad9-f92358905051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(training)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 1, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 1, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "  list([0, 1, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 1, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 1, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 0, 0, 1, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 0, 0, 1, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 1, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 1, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 0, 1])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 0, 0, 1, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 1, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 1, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "  list([0, 0, 1, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 1, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 0, 0, 1, 0, 0])]\n",
            " [list([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 0, 1])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 0, 1])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 1, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 1, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 1, 0, 0, 0])]\n",
            " [list([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
            "  list([1, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 1, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 1, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 0, 1])]\n",
            " [list([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 1, 0])]\n",
            " [list([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 1, 0, 0, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "  list([0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
            " [list([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "  list([1, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
            " [list([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  list([0, 0, 0, 0, 0, 0, 0, 0, 1])]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecwuKzP76hpO"
      },
      "source": [
        "train_x=list(training[:,0])\n",
        "train_y=list(training[:,1])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFc4truWDmzD"
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwR6Xt-yOnCw",
        "outputId": "86a81b1d-84a3-4f1c-af07-02e2ae542ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "net=tflearn.input_data(shape=[None,len(train_x[0])])\n",
        "net=tflearn.fully_connected(net,10)\n",
        "net=tflearn.fully_connected(net,10)\n",
        "net=tflearn.fully_connected(net,len(train_y[0]),activation='softmax')\n",
        "net=tflearn.regression(net)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-aE4ybPmBX",
        "outputId": "f2eac24a-b0c6-4ce0-8b03-890960df2b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model=tflearn.DNN(net,tensorboard_dir='tflearn_logs')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPu0c5hNPxVO",
        "outputId": "b8cfd85f-86cb-45ca-b4ae-f3781a7e6266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model.fit(train_x,train_y,n_epoch=1000,batch_size=8,show_metric=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 5999  | total loss: \u001b[1m\u001b[32m0.09655\u001b[0m\u001b[0m | time: 0.016s\n",
            "| Adam | epoch: 1000 | loss: 0.09655 - acc: 0.9990 -- iter: 40/47\n",
            "Training Step: 6000  | total loss: \u001b[1m\u001b[32m0.09367\u001b[0m\u001b[0m | time: 0.019s\n",
            "| Adam | epoch: 1000 | loss: 0.09367 - acc: 0.9991 -- iter: 47/47\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_WRebbLRHSP",
        "outputId": "01341e67-6058-4e13-96b1-a40a7a425258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.save('model.tflearn')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:/content/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJgJy2eNRbjp"
      },
      "source": [
        "import pickle\n",
        "pickle.dump({'words':words,'classes':classes,'train_x':train_x,'train_y':train_y},open(\"training_data\",\"wb\"))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHNlCsCoTHdI"
      },
      "source": [
        "data=pickle.load(open(\"training_data\",\"rb\"))\n",
        "words=data['words']\n",
        "classes=data['classes']\n",
        "train_x=data['train_x']\n",
        "train_y=data['train_y']\n",
        "with open('/content/intents.json') as json_data:\n",
        "  intents=json.load(json_data)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3HwiDWZd55N",
        "outputId": "4dedfaee-c62b-4578-d2dc-7a0c0c79b227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "model.load('./model.tflearn')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/model.tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNsZRILpeAGd"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  sentence_words=nltk.word_tokenize(sentence)\n",
        "  sentence_words=[stemmer.stem(word.lower()) for word in sentence_words]\n",
        "  return sentence_words"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjOCi4dadhxR"
      },
      "source": [
        "def bow(sentence,words,show_details=False):\n",
        "  sentence_words=clean_up_sentence(sentence)\n",
        "  bag=[0]*len(words)\n",
        "  for s in sentence_words:\n",
        "    for i,w in enumerate(words):\n",
        "      if w==s:\n",
        "        bag[i]=1\n",
        "        if show_details:\n",
        "          print(\"found in bag: %s\"%w)\n",
        "  return(np.array(bag))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD4QjsU1e5r1"
      },
      "source": [
        "ERROR_THRESHOLD=0.25\n",
        "context={}\n",
        "def classify(sentence):\n",
        "  results=model.predict([bow(sentence,words)])[0]\n",
        "  results=[[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "  results.sort(key=lambda x:x[1],reverse=True)\n",
        "  return_list=[]\n",
        "  for r in results:\n",
        "    return_list.append((classes[r[0]],r[1]))\n",
        "  return return_list"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od_CyJ29AZqL"
      },
      "source": [
        "def response(sentence,userID='123',show_details=False):\n",
        "  results=classify(sentence)\n",
        "  if results:\n",
        "    while results:\n",
        "      for i in intents['intents']:\n",
        "        if i['tag']==results[0][0]:\n",
        "          if 'context_set' in i:\n",
        "            if show_details:\n",
        "              print ('context:', i['context_set'])\n",
        "            context[userID] = i['context_set']\n",
        "          if not 'context_filter' in i or (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
        "            if show_details: print ('tag:', i['tag'])\n",
        "            return print(random.choice(i['responses']))\n",
        "          return print(random.choice(i['responses']))\n",
        "      results.pop(0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMiswKj3BNKT",
        "outputId": "922fc27e-608d-4fd4-9197-5766875979ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classify('hi')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('greeting', 0.73743254)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHOoD7qfCsYD",
        "outputId": "d6b1513a-7aaf-476b-caef-0efd73d6b21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "response('hi')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good to see you again\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU3b2B6PDdY0",
        "outputId": "06e5c741-166a-47bf-9590-aec9651e5aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classify('how are you?')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('greeting', 0.93775755)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs6bFq69DmNh",
        "outputId": "b9b620ad-35b8-4106-fdb7-dac5adc4c8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "response('how are you?')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi there, how can I help?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se6_czWsDpZy",
        "outputId": "d887f677-c854-41da-9096-fe00d3d59f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classify('Give me the menu.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoemLOU1DuRR"
      },
      "source": [
        "response('Give me the menu')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVu6L1M6Dxjg",
        "outputId": "9916784a-effb-48b1-e0e0-418c0bb96f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classify('What is the menu for today?')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('greeting', 0.75935256)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk89bPAWlDWl",
        "outputId": "8761b7d0-d0ea-4006-fd92-67033f412108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "response('What is the menu for today?')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi there, how can I help?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQsaHEqklN2s"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}